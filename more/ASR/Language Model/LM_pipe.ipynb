{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Utils.utils as ut\n",
    "import Utils.models as lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load vocab\n",
    "vocab = ut.loadVocab(\"vocab.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = \"corpus.txt\"\n",
    "train_data = ut.loadData(dataDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the training data \n",
    "preprocessed_train_data = ut.preprocess(train_data, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the language models\n",
    "unigramLM = lm.UnigramLM(vocab)\n",
    "bigramLM = lm.BigramLM(vocab)\n",
    "trigramLM = lm.TrigramLM(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the language models\n",
    "unigramLM.train(preprocessed_train_data)\n",
    "bigramLM.train(preprocessed_train_data)\n",
    "trigramLM.train(preprocessed_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the three language models in ARPA format like in corpus.3bo file\n",
    "# first print the data section of the file\n",
    "data_section = \"\\\\data\\\\\\n\"\n",
    "\n",
    "# print the trigram model\n",
    "bigrams = []\n",
    "tri_grams_number = 0\n",
    "trigram_section = \"\\\\3-grams:\\n\"\n",
    "for word1 in vocab:\n",
    "    for word2 in vocab:\n",
    "        for word3 in vocab:\n",
    "            if trigramLM.checkBackOff(word1, word2, word3):\n",
    "                bigrams.append((word1, word2))\n",
    "            else: \n",
    "                trigram_section += str(trigramLM.calcProbability(word1, word2, word3)) + \"\\t\" + word1 + \" \" + word2 + \" \" + word3 + \"\\n\"\n",
    "                tri_grams_number += 1\n",
    "\n",
    "# print the bigram model\n",
    "bigram_section = \"\\\\2-grams:\\n\"\n",
    "unigrams = []\n",
    "bi_grams_number = 0\n",
    "for word1 in vocab:\n",
    "    for word2 in vocab:\n",
    "        if bigramLM.checkBackOff(word1, word2):\n",
    "            unigrams.append(word1)\n",
    "        elif (word1, word2) in bigrams:\n",
    "            bigram_section += str(bigramLM.calcProbability(word1, word2)) + \"\\t\" + word1 + \" \" + word2 + \"\\t\" + str(ut.backOffWeight_bi_context((word1, word2), bigramLM, trigramLM)) + \"\\n\"\n",
    "            bi_grams_number += 1\n",
    "        else:\n",
    "            bigram_section += str(bigramLM.calcProbability(word1, word2)) + \"\\t\" + word1 + \" \" + word2 + \"\\n\"\n",
    "            bi_grams_number += 1\n",
    "\n",
    "# print the unigram model\n",
    "unigram_section = \"\\\\1-grams:\\n\"\n",
    "uni_grams_number = 0\n",
    "for word in vocab:\n",
    "    if not unigramLM.checkBackOff(word) and word in unigrams:\n",
    "        unigram_section += str(unigramLM.calcProbability(word)) + \"\\t\" + word1 + \"\\t\" + str(ut.backOffWeight_uni_context(word, bigramLM, unigramLM)) + \"\\n\"\n",
    "        uni_grams_number += 1 \n",
    "    elif not unigramLM.checkBackOff(word) and word not in unigrams:\n",
    "        unigram_section += str(unigramLM.calcProbability(word)) + \"\\t\" + word1 + \"\\n\"\n",
    "        uni_grams_number += 1 \n",
    "\n",
    "\n",
    "data_section += \"ngram 1=\" + str(uni_grams_number) + \"\\n\"\n",
    "data_section += \"ngram 2=\" + str(bi_grams_number) + \"\\n\"\n",
    "data_section += \"ngram 3=\" + str(tri_grams_number) + \"\\n\"\n",
    "\n",
    "# print end section\n",
    "end_section = \"\\\\end\\\\\"\n",
    "\n",
    "# print the whole file\n",
    "with open(\"LM.3bo\", 'w') as f:\n",
    "    f.write(\"\\n\" + data_section + \"\\n\" + unigram_section + \"\\n\" + bigram_section + \"\\n\" + trigram_section + \"\\n\" + end_section)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
