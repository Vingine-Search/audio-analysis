{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1c8f2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Some utility functions.\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import tqdm\n",
    "import random\n",
    "import importlib\n",
    "import subprocess\n",
    "import config\n",
    "import numpy as np\n",
    "from typing import List, Union, Tuple, Any\n",
    "\n",
    "\n",
    "def get_files_rec(path: str, forbidden=[], must_contain=[]) -> List[str]:\n",
    "    def _inner(path: str):\n",
    "        files = []\n",
    "        parent = path\n",
    "        for path in os.listdir(parent):\n",
    "            path = os.path.join(parent, path)\n",
    "            if os.path.isdir(path):\n",
    "                files.extend(_inner(path))\n",
    "            else:\n",
    "                files.append(path)\n",
    "        return files\n",
    "    files = _inner(path)\n",
    "    files = [file for file in files if all(forbid not in file for forbid in forbidden)]\n",
    "    if len(must_contain):\n",
    "        files = [file for file in files if any(must in file for must in must_contain)]\n",
    "    files.sort()\n",
    "    random.seed(config.random_seed)\n",
    "    random.shuffle(files)\n",
    "    return files\n",
    "\n",
    "def delete_template(tmpl: str):\n",
    "    i = 0\n",
    "    while os.path.exists(tmpl.replace('$', str(i))):\n",
    "        os.remove(tmpl.replace('$', str(i)))\n",
    "        i += 1\n",
    "\n",
    "def bar(it, *args, **kwargs) -> tqdm.tqdm:\n",
    "    TQDM_DEFAULT_SETTINGS = {\n",
    "        'colour': 'GREEN',\n",
    "        'file': sys.stdout,\n",
    "    }\n",
    "    kwargs = {**TQDM_DEFAULT_SETTINGS, **kwargs}\n",
    "    try:\n",
    "        if kwargs.get(\"total\") is None:\n",
    "            kwargs[\"total\"] = len(it)\n",
    "    except:\n",
    "        pass\n",
    "    return tqdm.tqdm(it, *args, **kwargs)\n",
    "\n",
    "def load_wordvecs(path: str, load_embs=False) -> Union[dict, Tuple[dict, Any]]:\n",
    "    \"\"\"A .vec word embeddings file to load the vocabulary and their embeddings from.\"\"\"\n",
    "    npz_path = path.removesuffix(\".vec\") + \".npz\"\n",
    "    if not os.path.exists(npz_path):\n",
    "        print(\"\\nWord embeddings are not prepared! Preparing them now.\")\n",
    "        print(\"This will take some time...\")\n",
    "        vec2npz(path)\n",
    "    word2vec = np.load(npz_path)\n",
    "    words = dict((w, i) for i, w in enumerate(word2vec[\"words\"]))\n",
    "    if not load_embs:\n",
    "        return words\n",
    "    # Loading the embeddings takes a lot of time.\n",
    "    return words, word2vec[\"embeddings\"]\n",
    "\n",
    "def vec2npz(path: str, extra_vocab=[]):\n",
    "    \"\"\"Converts a .vec embeddings to vocabulary and embeddings lists and stores\n",
    "    them as a compressed numpy array on the same path with .npz extension.\n",
    "    \"\"\"\n",
    "    with open(path) as f:\n",
    "        w_count, dim = f.readline().split()\n",
    "        w_count, dim = int(w_count), int(dim)\n",
    "        total_count = (w_count + len(extra_vocab))\n",
    "        words = [\"\"] * total_count\n",
    "        embeddings = np.zeros((total_count, dim), dtype=np.float32)\n",
    "        for i, line in enumerate(bar(f, total=w_count)):\n",
    "            word, emb = line.split(maxsplit=1)\n",
    "            words[i] = word\n",
    "            embeddings[i] = np.array(emb.split(), dtype=np.float32)\n",
    "        # Actual count can be less than the specified count in case of the vector file being trimmed.\n",
    "        actual_count = i + 1\n",
    "\n",
    "    np.random.seed(config.random_seed)\n",
    "    for i, word in enumerate(extra_vocab):\n",
    "        words[actual_count + i] = word\n",
    "        # This generates a random 300d array of values in range [-0.99, 0.99]\n",
    "        embeddings[actual_count + i] = 1.98 * np.random.rand(300).astype(np.float32) - 0.99\n",
    "    actual_count += len(extra_vocab)\n",
    "\n",
    "    # Convert the words array to a numpy array before storing.\n",
    "    words = np.array(words)\n",
    "\n",
    "    # Squeeze to the actual count.\n",
    "    embeddings = embeddings[:actual_count]\n",
    "    words = words[:actual_count]\n",
    "    print(\"Storing the prepared word embeddings in a .npz file.\")\n",
    "    npz_path = path.removesuffix(\".vec\") + \".npz\"\n",
    "    np.savez(npz_path, embeddings=embeddings, words=words)\n",
    "    print(\"Prepared word embeddings are now stored in: \", os.path.abspath(npz_path))\n",
    "\n",
    "def trim_vocab_from(path: str, word2vec_file_path: str) -> str:\n",
    "    \"\"\"Trims `word2vec_file_path` to a set that has only the words found in files in `path`.\n",
    "    The word2vec model we use have about one million unique words. But in spoken and written language,\n",
    "    people use less than 1% of that (10k words).\n",
    "    This helps in memory usage.\n",
    "    \"\"\"\n",
    "    vocab, embeddings = load_wordvecs(word2vec_file_path, load_embs=True)\n",
    "    vocab_set = set(vocab.keys())\n",
    "    words_in_files = set()\n",
    "    files = get_files_rec(path, must_contain=[\".preprocessed\"])\n",
    "    for file in files:\n",
    "        words = open(file).read().split()\n",
    "        words_in_files.update(words)\n",
    "    # Keep only the vocabs which appeared in the files we have.\n",
    "    vocab_set = vocab_set.intersection(words_in_files)\n",
    "    vocab = dict((word, vocab[word]) for word in vocab_set)\n",
    "    new_vocab = [\"\"] * len(vocab)\n",
    "    new_embeddings = np.zeros((len(new_vocab), embeddings.shape[1]), dtype=np.float32)\n",
    "    # Create the new vocab and embeddings maps.\n",
    "    for i, word in enumerate(vocab):\n",
    "        new_vocab[i] = word\n",
    "        new_embeddings[i] = embeddings[vocab[word]]\n",
    "    # Store the trimmed vocab.\n",
    "    npz_path = word2vec_file_path.removesuffix(\".vec\") + \"-trimmed.npz\"\n",
    "    np.savez(npz_path, embeddings=new_embeddings, words=new_vocab)\n",
    "    print(f\"Trimmed word embeddings (size={len(new_vocab)}) are now stored in: \", os.path.abspath(npz_path))\n",
    "    return npz_path.removesuffix(\".npz\") + \".vec\"\n",
    "\n",
    "def make_ascii(word: str) -> str:\n",
    "    return bytes(word, encoding='utf-8').decode('ascii', 'ignore').strip()\n",
    "\n",
    "def get_sub(link: str, fname: str):\n",
    "    \"\"\"Downloads the auto-generated subtitles from the youtube link `link` and persists them in `file`.\"\"\"\n",
    "    subprocess.run(f\"yt-dlp --write-auto-sub --skip-download \\\"{link}\\\" -o {fname}\", shell=True).check_returncode()\n",
    "    subprocess.run(f\"ffmpeg -y -i {fname}.en.vtt {fname}.srt\", shell=True).check_returncode()\n",
    "\n",
    "    with open(f\"{fname}.srt\") as file:\n",
    "        lines = file.readlines()\n",
    "        good_lines = []\n",
    "        i = 0\n",
    "        while i != len(lines):\n",
    "            try:\n",
    "                int(lines[i])\n",
    "                if lines[i + 1].__contains__('-->'):\n",
    "                    i += 2\n",
    "            except:\n",
    "                pass\n",
    "            good_lines.append(lines[i])\n",
    "            i += 1\n",
    "        with open(f\"{fname}.txt\", 'w') as file2:\n",
    "            for line in good_lines:\n",
    "                file2.write(line)\n",
    "\n",
    "    # SRT files contain duplicate lines for some reason, delete them.\n",
    "    with open(f\"{fname}.txt\") as file:\n",
    "        lines = file.readlines()\n",
    "        lines = [line.strip() for line in lines]\n",
    "        lines = [line for line in lines if line != '']\n",
    "        last_line = None\n",
    "        non_dup_lines = []\n",
    "        for line in lines:\n",
    "            if last_line == line:\n",
    "                continue\n",
    "            non_dup_lines.append(line)\n",
    "            last_line = line\n",
    "\n",
    "    with open(f\"{fname}.asr\", \"w\") as file:\n",
    "        file.write(' '.join(non_dup_lines))\n",
    "\n",
    "    # Remove the intermediate files.\n",
    "    os.remove(f\"{fname}.txt\")\n",
    "    os.remove(f\"{fname}.srt\")\n",
    "    os.remove(f\"{fname}.en.vtt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7772c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Preprocess the wiki data by removing the stop words, punctuation and\n",
    "irrelevant parts to make it look more like an ASR output.\"\"\"\n",
    "\n",
    "import os\n",
    "import nltk\n",
    "import utils\n",
    "import config\n",
    "import string\n",
    "from typing import Tuple, List\n",
    "\n",
    "useless_tags = {\"***LIST***\"}\n",
    "try:\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english')).union(useless_tags)\n",
    "except:\n",
    "    nltk.download('stopwords')\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english')).union(useless_tags)\n",
    "\n",
    "def recoverable_clean_section(section: str, vocab: dict) -> Tuple[str, List[str]]:\n",
    "    \"\"\"This is similar to clean_section but it stores the information about the original\n",
    "    structure of the text stream so we can recover the correct splits in the input.\n",
    "    \"\"\"\n",
    "    # Remove any punctuation.\n",
    "    for p in string.punctuation:\n",
    "        section = section.replace(p, ' ')\n",
    "    words = [w.lower().strip() for w in section.split()]\n",
    "    words = [w for w in words if w]\n",
    "    original, clean_sec = [], []\n",
    "    for word in words:\n",
    "        ascii_word = utils.make_ascii(word)\n",
    "        # Remove stop words, unknown words and non-ascii words.\n",
    "        if not ascii_word or ascii_word in stop_words or ascii_word not in vocab:\n",
    "            # 0 indicates that we missed this word.\n",
    "            original.append(word)\n",
    "        else:\n",
    "            # 1 indicates that we took this word into account.\n",
    "            original.append(word)\n",
    "            clean_sec.append(ascii_word)\n",
    "    return ' '.join(clean_sec), original\n",
    "\n",
    "def clean_section(section: str, vocab: dict) -> str:\n",
    "    return recoverable_clean_section(section, vocab)[0]\n",
    "\n",
    "def process_doc(document: str, vocab: dict):\n",
    "    lines = [l for l in document.split('\\n') if l]\n",
    "\n",
    "    # Divide the document into sections.\n",
    "    sections, i = [], 0\n",
    "    while i < len(lines):\n",
    "        if lines[i].startswith(config.section_start):\n",
    "            i += 1\n",
    "            start = i\n",
    "            while i < len(lines) and not lines[i].startswith(config.section_start):\n",
    "                i += 1\n",
    "            end = i\n",
    "            sections.append(' '.join(lines[start:end]))\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    # Rejoin the sections together.\n",
    "    document = []\n",
    "    for section in sections:\n",
    "        section = clean_section(section, vocab)\n",
    "        # Omit sections that are very short (doesn't meet the min words per sec requirement).\n",
    "        if len(section.split()) >= config.min_words_per_section:\n",
    "            document.append(section)\n",
    "    return \"\\n\\n\".join(document)\n",
    "\n",
    "def preprocess_wiki(wiki_path):\n",
    "    # Only grab files with no extension (no .preprocessed/.tf/.anything files).\n",
    "    files = utils.get_files_rec(wiki_path, forbidden=['.'])\n",
    "    vocab = utils.load_wordvecs(config.word2vec_file_path)\n",
    "    print(\"\\nPreprocessing the files in\", os.path.abspath(wiki_path))\n",
    "    for file in utils.bar(files):\n",
    "        document = open(file).read()\n",
    "        open(file + \".preprocessed\", 'w').write(process_doc(document, vocab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9bb2751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import utils\n",
    "import config\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "\n",
    "NEW_TOPIC_MARKER = \"NEW_TOPIC_MARKER\"\n",
    "\n",
    "\n",
    "def read_files(files):\n",
    "    for file in files:\n",
    "        yield open(file).read().replace(\"\\n\\n\", \" \" + NEW_TOPIC_MARKER + \" \")\n",
    "\n",
    "def segment_generator(reader):\n",
    "    segment = []\n",
    "    for doc in reader:\n",
    "        # A new document is considered a topical change.\n",
    "        had_marker = True\n",
    "        for word in doc.split():\n",
    "            if word == NEW_TOPIC_MARKER:\n",
    "                had_marker = True\n",
    "            else:\n",
    "                segment.append(word)\n",
    "                if len(segment) == config.segment_length:\n",
    "                    yield (segment, had_marker)\n",
    "                    # Reset the segment and the marker.\n",
    "                    segment, had_marker = [], False\n",
    "\n",
    "def write_segment(segment, writer, vocab):\n",
    "    words, topic_boundary = segment\n",
    "    # All the words should be in our vocabulary since we eliminated unknown words while preprocessing.\n",
    "    tokens = [vocab[w] for w in words]\n",
    "    record = tf.train.SequenceExample()\n",
    "    record.context.feature[\"topic_bound\"].int64_list.value.append(topic_boundary)\n",
    "    tok_seq = record.feature_lists.feature_list[\"token_sequence\"]\n",
    "    for token in tokens:\n",
    "        tok_seq.feature.add().int64_list.value.append(token)\n",
    "    writer.write(record.SerializeToString())\n",
    "\n",
    "def record_gen_predict(asr: str, record_path_template: str):\n",
    "    \"\"\"Same as record_gen but works on only one input document.\n",
    "    More suitable for predicting.\n",
    "    \"\"\"\n",
    "    vocab = utils.load_wordvecs(config.word2vec_file_path)\n",
    "    writer = tf.io.TFRecordWriter(record_path_template.replace('$', '0'))\n",
    "    for segment in segment_generator([asr]):\n",
    "        write_segment(segment, writer, vocab)\n",
    "    print(\"Generated records are stored in\", os.path.abspath(record_path_template))\n",
    "\n",
    "def record_gen(input_dir_path: str, record_path_template: str):\n",
    "    utils.delete_template(record_path_template)\n",
    "    files = utils.get_files_rec(input_dir_path, must_contain=[\".preprocessed\"])\n",
    "    if len(files) == 0:\n",
    "        print(\"WARNING: There are no .preprocessed files in\", input_dir_path)\n",
    "    print(\"\\nGenerating TF records for the preprocessed files in\", os.path.abspath(input_dir_path))\n",
    "    # Don't load all the files in memory at once, create a lazy file reader instead.\n",
    "    reader = read_files(utils.bar(files))\n",
    "    vocab = utils.load_wordvecs(config.word2vec_file_path)\n",
    "    for index, segment in enumerate(segment_generator(reader)):\n",
    "        # Refresh the writer to parallelize the IO as much as possible when reading.\n",
    "        if index % config.segments_per_tfrecord == 0:\n",
    "            writer = tf.io.TFRecordWriter(record_path_template.replace('$', str(index // config.segments_per_tfrecord)))\n",
    "        write_segment(segment, writer, vocab)\n",
    "    print(\"Generated records are stored in\", os.path.abspath(record_path_template))\n",
    "\n",
    "def input_fn(record_path_template: str):\n",
    "    def make_dataset(deserializer):\n",
    "        paths, index = [], 0\n",
    "        while os.path.exists(record_path_template.replace('$', str(index))):\n",
    "            paths.append(record_path_template.replace('$', str(index)))\n",
    "            index += 1\n",
    "        dataset = tf.data.TFRecordDataset(paths)\n",
    "        dataset = dataset.repeat(config.epochs)\n",
    "        dataset = dataset.map(deserializer, num_parallel_calls=128)\n",
    "        # Create a sliding window over the data with a `snippet_stride` slider size.\n",
    "        dataset = dataset.window(size=config.snippet_length, shift=config.snippet_stride, drop_remainder=True)\n",
    "        # Join the windows back together. (This outputs every window batched instead of being a `_VariantDataset`).\n",
    "        dataset = dataset.flat_map(lambda window: window.batch(config.snippet_length))\n",
    "        # Batch every `config.batch_size` windows together as one training example.\n",
    "        dataset = dataset.batch(config.batch_size, drop_remainder=True)\n",
    "        # Buffer some batches to lower the IO latency.\n",
    "        dataset = dataset.prefetch(20)\n",
    "        return tf.compat.v1.data.make_one_shot_iterator(dataset).get_next()\n",
    "\n",
    "    def deserialize_labels(sr):\n",
    "        return tf.io.parse_single_sequence_example(serialized=sr, context_features={\"topic_bound\": tf.io.FixedLenFeature([], dtype=tf.int64)})[0][\"topic_bound\"]\n",
    "    def deserialize_features(sr):\n",
    "        return tf.io.parse_single_sequence_example(serialized=sr, sequence_features={\"token_sequence\": tf.io.FixedLenSequenceFeature([], dtype=tf.int64)})[1][\"token_sequence\"]\n",
    "    def deserialize(serialized_record):\n",
    "        context_parsed, sequence_parsed = tf.io.parse_single_sequence_example(\n",
    "            serialized=serialized_record,\n",
    "            context_features={\"topic_bound\": tf.io.FixedLenFeature([], dtype=tf.int64)},\n",
    "            sequence_features={\"token_sequence\": tf.io.FixedLenSequenceFeature([], dtype=tf.int64)},\n",
    "        )\n",
    "        return (sequence_parsed[\"token_sequence\"], context_parsed[\"topic_bound\"])\n",
    "\n",
    "    return make_dataset(deserialize_features), make_dataset(deserialize_labels)\n",
    "\n",
    "\n",
    "def get_batch_count(record_path_template: str):\n",
    "    paths, index = [], 0\n",
    "    while os.path.exists(record_path_template.replace('$', str(index))):\n",
    "        paths.append(record_path_template.replace('$', str(index)))\n",
    "        index += 1\n",
    "    # Assuming every tf record is full. This is a pessimistic estimation.\n",
    "    # Also assuming `config.segments_per_tfrecord` have changed sense the record generation.\n",
    "    segment_count = index * config.epochs * config.segments_per_tfrecord\n",
    "    snippet_count = segment_count // config.snippet_stride\n",
    "    batch_count = snippet_count // config.batch_size\n",
    "    return batch_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "056a4744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import utils\n",
    "import config\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformer.model import transformer, model_utils\n",
    "\n",
    "\n",
    "def model_fn(features, labels, mode, params):\n",
    "    prints = []\n",
    "    def out(*args, **kwargs):\n",
    "        prints.append(tf.print(args, kwargs, output_stream=sys.stdout))\n",
    "    def uniform(s):\n",
    "        return tf.initializers.GlorotUniform()(s)\n",
    "\n",
    "    predicting = mode == tf.estimator.ModeKeys.PREDICT\n",
    "    if not predicting:\n",
    "        TT_PARAMS = config.token_transformer_training_params\n",
    "        ST_PARAMS = config.sentence_transformer_training_params\n",
    "    else:\n",
    "        TT_PARAMS = config.token_transformer_prediction_params\n",
    "        ST_PARAMS = config.sentence_transformer_prediction_params\n",
    "\n",
    "    embeddings = tf.convert_to_tensor(params[\"embeddings\"])\n",
    "    snippet_batch = tf.reshape(features, [config.batch_size, config.snippet_length, config.segment_length])\n",
    "\n",
    "    # The distributions used for positional embeddings. Each, segment & snippet level positions take half the `config.positional_embeddings_length`.\n",
    "    token_positional_embeddings_dist = tf.Variable(uniform([config.segment_length, config.positional_embeddings_length // 2]))\n",
    "    sentence_positional_embeddings_dist = tf.Variable(uniform([config.snippet_length, config.positional_embeddings_length // 2]))\n",
    "\n",
    "    # Arrays with the same shape as `snippet_batch` that has the nominal positions of the token on a segment level and snippet level.\n",
    "    token_nominal_positions = np.tile(np.arange(config.segment_length), [config.batch_size, config.snippet_length, 1])\n",
    "    sentence_nominal_positions = np.tile(np.tile(np.arange(config.snippet_length), [config.segment_length, 1]).T, [config.batch_size, 1, 1])\n",
    "\n",
    "    # Look up the word and positional embeddings and concatenate them together as the final embeddings.\n",
    "    snippet_batch_embeddings = tf.nn.embedding_lookup(embeddings, snippet_batch)\n",
    "    token_positional_embeddings = tf.nn.embedding_lookup(token_positional_embeddings_dist, token_nominal_positions)\n",
    "    sentence_positional_embeddings = tf.nn.embedding_lookup(sentence_positional_embeddings_dist, sentence_nominal_positions)\n",
    "    snippet_batch_embeddings = tf.concat([snippet_batch_embeddings, token_positional_embeddings, sentence_positional_embeddings], axis=3)\n",
    "\n",
    "    # Token-level transformer (TT):\n",
    "    hidden_size = embeddings.shape[1] + config.positional_embeddings_length\n",
    "    tt_input = tf.reshape(snippet_batch_embeddings, [config.batch_size * config.snippet_length, config.segment_length, hidden_size])\n",
    "    TT_PARAMS.update({\"hidden_size\": hidden_size})\n",
    "    tt_trans = transformer.EncoderStack(TT_PARAMS, mode)\n",
    "    # Since we don't have any padding in our input, the padding is gonna be all zeros.\n",
    "    attention_padding = tf.zeros([config.batch_size * config.snippet_length, config.segment_length])\n",
    "    attention_bias = model_utils.get_padding_bias(attention_padding, padding_value=-1)\n",
    "    tt_output = tt_trans(tt_input, attention_bias, attention_padding)\n",
    "    # We will use the first and last token to represent the sentence.\n",
    "    sentence_embeddings = tf.concat([tt_output[:, 0, :], tt_output[:, -1, :]], axis=1)\n",
    "\n",
    "    # Sentence-level transformer (ST):\n",
    "    hidden_size = sentence_embeddings.shape[1]\n",
    "    st_input = tf.reshape(sentence_embeddings, [config.batch_size, config.snippet_length, hidden_size])\n",
    "    ST_PARAMS.update({\"hidden_size\": hidden_size})\n",
    "    st_trans = transformer.EncoderStack(ST_PARAMS, mode)\n",
    "    # No padding here as well.\n",
    "    attention_padding = tf.zeros([config.batch_size, config.snippet_length])\n",
    "    attention_bias = model_utils.get_padding_bias(attention_padding, padding_value=-1)\n",
    "    st_output = st_trans(st_input, attention_bias, attention_padding)\n",
    "\n",
    "    # Segmentation classifier:\n",
    "    seg_classifier_w = tf.Variable(uniform([st_output.shape[2], 2]))\n",
    "    seg_classifier_b = tf.Variable(uniform([2]))\n",
    "    seg_probabilities = tf.nn.softmax(tf.add(tf.tensordot(st_output, seg_classifier_w, axes=[[2], [0]]), seg_classifier_b))\n",
    "\n",
    "    if not predicting:\n",
    "        # Prepare segment labels:\n",
    "        labels = tf.reshape(labels, [config.batch_size, config.snippet_length])\n",
    "        label_2d_fn = lambda x: tf.cond(tf.equal(x, 1), lambda: tf.constant([0., 1.]), lambda: tf.constant([1., 0.]))\n",
    "        segment_labels = tf.map_fn(lambda x: tf.map_fn(label_2d_fn, x, dtype=tf.float32), labels, dtype=tf.float32)\n",
    "\n",
    "        # Define the loss:\n",
    "        segmentation_loss = -1 * tf.reduce_sum(tf.multiply(tf.math.log(seg_probabilities), segment_labels))\n",
    "        tf.summary.scalar(\"Segmentation Loss\", segmentation_loss)\n",
    "\n",
    "        optimizer_seg = tf.compat.v1.train.AdamOptimizer(learning_rate=config.learning_rate)\n",
    "        # Make this statement depend on the prints we have above to not optimize them away.\n",
    "        with tf.control_dependencies(prints):\n",
    "            train_op = optimizer_seg.minimize(segmentation_loss, tf.compat.v1.train.get_global_step())\n",
    "\n",
    "        print(\"Model defined.\")\n",
    "        return tf.estimator.EstimatorSpec(mode, loss=segmentation_loss, train_op=train_op)\n",
    "    else:\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=seg_probabilities)\n",
    "\n",
    "\n",
    "def train(tfrecord_tmpl):\n",
    "    print(\"Loading the word2vec model...\")\n",
    "    _, embeddings = utils.load_wordvecs(config.word2vec_file_path, load_embs=True)\n",
    "    model_conf = tf.estimator.RunConfig(model_dir=config.model_dir)\n",
    "    estimator = tf.estimator.Estimator(model_fn=model_fn, config=model_conf, params={\"embeddings\": embeddings})\n",
    "    print(\"Training...\")\n",
    "    estimator.train(input_fn=lambda: input_fn(tfrecord_tmpl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93b1d13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d17d4e",
   "metadata": {},
   "source": [
    "# Perform preprocessing (ASR-Like) and tf record generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40b5d80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(config)\n",
    "\n",
    "input_dirs = [\"data/wiki_727K/train\", \"data/wiki_727K/dev\", \"data/wiki_727K/test\"]\n",
    "input_dirs = []\n",
    "for input_dir in input_dirs:\n",
    "    tfrecord_tmpl = os.path.join(input_dir, config.tfrecord_tmpl)\n",
    "    # Preprocess the documents.\n",
    "    preprocess_wiki(input_dir)\n",
    "    # Generate the tensorflow records.\n",
    "    record_gen(input_dir, tfrecord_tmpl)\n",
    "    print(f\"Number of {input_dir} examples =\", get_batch_count(tfrecord_tmpl))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f71856",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f055c154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples = 232857\n",
      "Loading the word2vec model...\n",
      "Loaded wordvecs.\n",
      "WARNING:tensorflow:From /tmp/ipykernel_11470/4067839002.py:12: RunConfig.__init__ (from tensorflow_estimator.python.estimator.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From /tmp/ipykernel_11470/4067839002.py:13: Estimator.__init__ (from tensorflow_estimator.python.estimator.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'data/model/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "Training...\n",
      "WARNING:tensorflow:From /home/mario/.local/share/virtualenvs/topic-segmentation-ivNeB2ii/lib/python3.10/site-packages/tensorflow/python/training/training_util.py:396: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /home/mario/.local/share/virtualenvs/topic-segmentation-ivNeB2ii/lib/python3.10/site-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "Model defined.\n",
      "WARNING:tensorflow:From /tmp/ipykernel_11470/3093034435.py:85: EstimatorSpec.__new__ (from tensorflow_estimator.python.estimator.model_fn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "WARNING:tensorflow:From /home/mario/.local/share/virtualenvs/topic-segmentation-ivNeB2ii/lib/python3.10/site-packages/tensorflow_estimator/python/estimator/estimator.py:1414: NanTensorHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From /home/mario/.local/share/virtualenvs/topic-segmentation-ivNeB2ii/lib/python3.10/site-packages/tensorflow_estimator/python/estimator/estimator.py:1417: LoggingTensorHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From /home/mario/.local/share/virtualenvs/topic-segmentation-ivNeB2ii/lib/python3.10/site-packages/tensorflow/python/training/basic_session_run_hooks.py:232: SecondOrStepTimer.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From /home/mario/.local/share/virtualenvs/topic-segmentation-ivNeB2ii/lib/python3.10/site-packages/tensorflow_estimator/python/estimator/estimator.py:1454: CheckpointSaverHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "WARNING:tensorflow:From /home/mario/.local/share/virtualenvs/topic-segmentation-ivNeB2ii/lib/python3.10/site-packages/tensorflow/python/training/monitored_session.py:579: StepCounterHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From /home/mario/.local/share/virtualenvs/topic-segmentation-ivNeB2ii/lib/python3.10/site-packages/tensorflow/python/training/monitored_session.py:586: SummarySaverHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from data/model/model.ckpt-168571\n",
      "WARNING:tensorflow:From /home/mario/.local/share/virtualenvs/topic-segmentation-ivNeB2ii/lib/python3.10/site-packages/tensorflow/python/training/saver.py:1176: get_checkpoint_mtimes (from tensorflow.python.checkpoint.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 168571...\n",
      "INFO:tensorflow:Saving checkpoints for 168571 into data/model/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 168571...\n",
      "WARNING:tensorflow:From /home/mario/.local/share/virtualenvs/topic-segmentation-ivNeB2ii/lib/python3.10/site-packages/tensorflow/python/training/monitored_session.py:1455: SessionRunArgs.__new__ (from tensorflow.python.training.session_run_hook) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From /home/mario/.local/share/virtualenvs/topic-segmentation-ivNeB2ii/lib/python3.10/site-packages/tensorflow/python/training/monitored_session.py:1454: SessionRunContext.__init__ (from tensorflow.python.training.session_run_hook) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From /home/mario/.local/share/virtualenvs/topic-segmentation-ivNeB2ii/lib/python3.10/site-packages/tensorflow/python/training/monitored_session.py:1474: SessionRunValues.__new__ (from tensorflow.python.training.session_run_hook) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "INFO:tensorflow:loss = 36.93342, step = 168571\n",
      "INFO:tensorflow:global_step/sec: 4.07732\n",
      "INFO:tensorflow:loss = 44.21216, step = 168671 (24.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.43782\n",
      "INFO:tensorflow:loss = 45.22246, step = 168771 (41.021 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.8144\n",
      "INFO:tensorflow:loss = 40.01558, step = 168871 (55.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.96607\n",
      "INFO:tensorflow:loss = 24.03732, step = 168971 (50.851 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.79214\n",
      "INFO:tensorflow:loss = 39.505657, step = 169071 (55.799 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82334\n",
      "INFO:tensorflow:loss = 40.672222, step = 169171 (54.858 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.83675\n",
      "INFO:tensorflow:loss = 26.557528, step = 169271 (54.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.02219\n",
      "INFO:tensorflow:loss = 30.856524, step = 169371 (49.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.9787\n",
      "INFO:tensorflow:loss = 31.310389, step = 169471 (50.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.75465\n",
      "INFO:tensorflow:loss = 39.220154, step = 169571 (56.992 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.86896\n",
      "INFO:tensorflow:loss = 40.742737, step = 169671 (53.506 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 169755...\n",
      "INFO:tensorflow:Saving checkpoints for 169755 into data/model/model.ckpt.\n",
      "WARNING:tensorflow:From /home/mario/.local/share/virtualenvs/topic-segmentation-ivNeB2ii/lib/python3.10/site-packages/tensorflow/python/training/saver.py:1067: remove_checkpoint (from tensorflow.python.checkpoint.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 169755...\n",
      "INFO:tensorflow:global_step/sec: 1.78342\n",
      "INFO:tensorflow:loss = 44.67749, step = 169771 (56.080 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80509\n",
      "INFO:tensorflow:loss = 34.614655, step = 169871 (55.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.68264\n",
      "INFO:tensorflow:loss = 32.485435, step = 169971 (59.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.91966\n",
      "INFO:tensorflow:loss = 34.609154, step = 170071 (52.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.78538\n",
      "INFO:tensorflow:loss = 43.673695, step = 170171 (56.010 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.77682\n",
      "INFO:tensorflow:loss = 48.42498, step = 170271 (56.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.88029\n",
      "INFO:tensorflow:loss = 39.39153, step = 170371 (53.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.84771\n",
      "INFO:tensorflow:loss = 31.954092, step = 170471 (54.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.84622\n",
      "INFO:tensorflow:loss = 30.776321, step = 170571 (54.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.09563\n",
      "INFO:tensorflow:loss = 27.824327, step = 170671 (47.723 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.42728\n",
      "INFO:tensorflow:loss = 35.513683, step = 170771 (41.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.74737\n",
      "INFO:tensorflow:loss = 36.221645, step = 170871 (36.398 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 170939...\n",
      "INFO:tensorflow:Saving checkpoints for 170939 into data/model/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 170939...\n",
      "INFO:tensorflow:global_step/sec: 2.85773\n",
      "INFO:tensorflow:loss = 47.463753, step = 170971 (35.000 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.08152\n",
      "INFO:tensorflow:loss = 38.87281, step = 171071 (32.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.37626\n",
      "INFO:tensorflow:loss = 41.168568, step = 171171 (29.625 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.23197\n",
      "INFO:tensorflow:loss = 31.644226, step = 171271 (30.936 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.1705\n",
      "INFO:tensorflow:loss = 34.767086, step = 171371 (31.545 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.10078\n",
      "INFO:tensorflow:loss = 45.244698, step = 171471 (32.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.22987\n",
      "INFO:tensorflow:loss = 37.60257, step = 171571 (30.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.5301\n",
      "INFO:tensorflow:loss = 40.944458, step = 171671 (39.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.83932\n",
      "INFO:tensorflow:loss = 37.277283, step = 171771 (54.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.69424\n",
      "INFO:tensorflow:loss = 24.854668, step = 171871 (59.022 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.7032\n",
      "INFO:tensorflow:loss = 34.692146, step = 171971 (58.713 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.76068\n",
      "INFO:tensorflow:loss = 45.546394, step = 172071 (56.802 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.22292\n",
      "INFO:tensorflow:loss = 34.830738, step = 172171 (44.985 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.38091\n",
      "INFO:tensorflow:loss = 38.517807, step = 172271 (42.001 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.47034\n",
      "INFO:tensorflow:loss = 39.560234, step = 172371 (40.482 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 172384...\n",
      "INFO:tensorflow:Saving checkpoints for 172384 into data/model/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 172384...\n",
      "INFO:tensorflow:global_step/sec: 2.46039\n",
      "INFO:tensorflow:loss = 19.875008, step = 172471 (40.636 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.51501\n",
      "INFO:tensorflow:loss = 42.27086, step = 172571 (39.761 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.64606\n",
      "INFO:tensorflow:loss = 39.302433, step = 172671 (60.756 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43449\n",
      "INFO:tensorflow:loss = 27.627594, step = 172771 (69.709 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48825\n",
      "INFO:tensorflow:loss = 23.52201, step = 172871 (67.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.20806\n",
      "INFO:tensorflow:loss = 39.69615, step = 172971 (82.780 sec)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m estimator \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mestimator\u001b[39m.\u001b[39mEstimator(model_fn\u001b[39m=\u001b[39mmodel_fn, config\u001b[39m=\u001b[39mmodel_conf, params\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39membeddings\u001b[39m\u001b[39m\"\u001b[39m: embeddings})\n\u001b[1;32m     15\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTraining...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m estimator\u001b[39m.\u001b[39;49mtrain(input_fn\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m: input_fn(tfrecord_tmpl))\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/topic-segmentation-ivNeB2ii/lib/python3.10/site-packages/tensorflow_estimator/python/estimator/estimator.py:360\u001b[0m, in \u001b[0;36mEstimator.train\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    357\u001b[0m hooks\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_convert_train_steps_to_hooks(steps, max_steps))\n\u001b[1;32m    359\u001b[0m saving_listeners \u001b[39m=\u001b[39m _check_listeners_type(saving_listeners)\n\u001b[0;32m--> 360\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_model(input_fn, hooks, saving_listeners)\n\u001b[1;32m    361\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mLoss for final step: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m, loss)\n\u001b[1;32m    362\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/topic-segmentation-ivNeB2ii/lib/python3.10/site-packages/tensorflow_estimator/python/estimator/estimator.py:1186\u001b[0m, in \u001b[0;36mEstimator._train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1184\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_model_distributed(input_fn, hooks, saving_listeners)\n\u001b[1;32m   1185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1186\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_model_default(input_fn, hooks, saving_listeners)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/topic-segmentation-ivNeB2ii/lib/python3.10/site-packages/tensorflow_estimator/python/estimator/estimator.py:1217\u001b[0m, in \u001b[0;36mEstimator._train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1214\u001b[0m estimator_spec \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_model_fn(features, labels, ModeKeys\u001b[39m.\u001b[39mTRAIN,\n\u001b[1;32m   1215\u001b[0m                                      \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig)\n\u001b[1;32m   1216\u001b[0m global_step_tensor \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mtrain\u001b[39m.\u001b[39mget_global_step(g)\n\u001b[0;32m-> 1217\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1218\u001b[0m                                        hooks, global_step_tensor,\n\u001b[1;32m   1219\u001b[0m                                        saving_listeners)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/topic-segmentation-ivNeB2ii/lib/python3.10/site-packages/tensorflow_estimator/python/estimator/estimator.py:1533\u001b[0m, in \u001b[0;36mEstimator._train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1530\u001b[0m   \u001b[39m# just as keras(https://github.com/tensorflow/tensorflow/blob/v2.4.1/tensorflow/python/keras/engine/training.py#L1093),\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m   \u001b[39m# trace should be enabled for every step\u001b[39;00m\n\u001b[1;32m   1532\u001b[0m   \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m, step_num\u001b[39m=\u001b[39mcurrent_step, _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m-> 1533\u001b[0m     _, loss \u001b[39m=\u001b[39m mon_sess\u001b[39m.\u001b[39;49mrun([estimator_spec\u001b[39m.\u001b[39;49mtrain_op, estimator_spec\u001b[39m.\u001b[39;49mloss])\n\u001b[1;32m   1534\u001b[0m \u001b[39mif\u001b[39;00m current_step \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1535\u001b[0m   tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mlogging\u001b[39m.\u001b[39mwarn(\u001b[39m'\u001b[39m\u001b[39mTraining with estimator made no steps. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1536\u001b[0m                             \u001b[39m'\u001b[39m\u001b[39mPerhaps input is empty or misspecified.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/topic-segmentation-ivNeB2ii/lib/python3.10/site-packages/tensorflow/python/training/monitored_session.py:778\u001b[0m, in \u001b[0;36m_MonitoredSession.run\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(\u001b[39mself\u001b[39m, fetches, feed_dict\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, options\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, run_metadata\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    765\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Run ops in the monitored session.\u001b[39;00m\n\u001b[1;32m    766\u001b[0m \n\u001b[1;32m    767\u001b[0m \u001b[39m  This method is completely compatible with the `tf.Session.run()` method.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[39m    Same as `tf.Session.run()`.\u001b[39;00m\n\u001b[1;32m    777\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sess\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m    779\u001b[0m       fetches,\n\u001b[1;32m    780\u001b[0m       feed_dict\u001b[39m=\u001b[39;49mfeed_dict,\n\u001b[1;32m    781\u001b[0m       options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m    782\u001b[0m       run_metadata\u001b[39m=\u001b[39;49mrun_metadata)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/topic-segmentation-ivNeB2ii/lib/python3.10/site-packages/tensorflow/python/training/monitored_session.py:1307\u001b[0m, in \u001b[0;36m_RecoverableSession.run\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sess:\n\u001b[1;32m   1306\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sess \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_session()\n\u001b[0;32m-> 1307\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sess\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m   1308\u001b[0m       fetches,\n\u001b[1;32m   1309\u001b[0m       feed_dict\u001b[39m=\u001b[39;49mfeed_dict,\n\u001b[1;32m   1310\u001b[0m       options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m   1311\u001b[0m       run_metadata\u001b[39m=\u001b[39;49mrun_metadata)\n\u001b[1;32m   1312\u001b[0m \u001b[39mexcept\u001b[39;00m _PREEMPTION_ERRORS \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1313\u001b[0m   logging\u001b[39m.\u001b[39minfo(\n\u001b[1;32m   1314\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mAn error was raised. This may be due to a preemption in \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1315\u001b[0m       \u001b[39m'\u001b[39m\u001b[39ma connected worker or parameter server. The current \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1320\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mincreasing the number of parameter servers assigned to \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1321\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mthe job. Error: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m, e)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/topic-segmentation-ivNeB2ii/lib/python3.10/site-packages/tensorflow/python/training/monitored_session.py:1397\u001b[0m, in \u001b[0;36m_CoordinatedSession.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1395\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1396\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1397\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sess\u001b[39m.\u001b[39;49mrun(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1398\u001b[0m   \u001b[39mexcept\u001b[39;00m _PREEMPTION_ERRORS:\n\u001b[1;32m   1399\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/topic-segmentation-ivNeB2ii/lib/python3.10/site-packages/tensorflow/python/training/monitored_session.py:1464\u001b[0m, in \u001b[0;36m_HookedSession.run\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[39m# Do session run.\u001b[39;00m\n\u001b[1;32m   1463\u001b[0m run_metadata \u001b[39m=\u001b[39m run_metadata \u001b[39mor\u001b[39;00m config_pb2\u001b[39m.\u001b[39mRunMetadata()\n\u001b[0;32m-> 1464\u001b[0m outputs \u001b[39m=\u001b[39m _WrappedSession\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m   1465\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1466\u001b[0m     fetches\u001b[39m=\u001b[39;49mactual_fetches,\n\u001b[1;32m   1467\u001b[0m     feed_dict\u001b[39m=\u001b[39;49mfeed_dict,\n\u001b[1;32m   1468\u001b[0m     options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m   1469\u001b[0m     run_metadata\u001b[39m=\u001b[39;49mrun_metadata)\n\u001b[1;32m   1471\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hooks:\n\u001b[1;32m   1472\u001b[0m   hook\u001b[39m.\u001b[39mafter_run(\n\u001b[1;32m   1473\u001b[0m       run_context,\n\u001b[1;32m   1474\u001b[0m       session_run_hook\u001b[39m.\u001b[39mSessionRunValues(\n\u001b[1;32m   1475\u001b[0m           results\u001b[39m=\u001b[39moutputs[hook] \u001b[39mif\u001b[39;00m hook \u001b[39min\u001b[39;00m outputs \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1476\u001b[0m           options\u001b[39m=\u001b[39moptions,\n\u001b[1;32m   1477\u001b[0m           run_metadata\u001b[39m=\u001b[39mrun_metadata))\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/topic-segmentation-ivNeB2ii/lib/python3.10/site-packages/tensorflow/python/training/monitored_session.py:1228\u001b[0m, in \u001b[0;36m_WrappedSession.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m-> 1228\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sess\u001b[39m.\u001b[39;49mrun(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/topic-segmentation-ivNeB2ii/lib/python3.10/site-packages/tensorflow/python/client/session.py:968\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    965\u001b[0m run_metadata_ptr \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_NewBuffer() \u001b[39mif\u001b[39;00m run_metadata \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    967\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 968\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(\u001b[39mNone\u001b[39;49;00m, fetches, feed_dict, options_ptr,\n\u001b[1;32m    969\u001b[0m                      run_metadata_ptr)\n\u001b[1;32m    970\u001b[0m   \u001b[39mif\u001b[39;00m run_metadata:\n\u001b[1;32m    971\u001b[0m     proto_data \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/topic-segmentation-ivNeB2ii/lib/python3.10/site-packages/tensorflow/python/client/session.py:1191\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1188\u001b[0m \u001b[39m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[1;32m   1189\u001b[0m \u001b[39m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[1;32m   1190\u001b[0m \u001b[39mif\u001b[39;00m final_fetches \u001b[39mor\u001b[39;00m final_targets \u001b[39mor\u001b[39;00m (handle \u001b[39mand\u001b[39;00m feed_dict_tensor):\n\u001b[0;32m-> 1191\u001b[0m   results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_run(handle, final_targets, final_fetches,\n\u001b[1;32m   1192\u001b[0m                          feed_dict_tensor, options, run_metadata)\n\u001b[1;32m   1193\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1194\u001b[0m   results \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/topic-segmentation-ivNeB2ii/lib/python3.10/site-packages/tensorflow/python/client/session.py:1371\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1368\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[1;32m   1370\u001b[0m \u001b[39mif\u001b[39;00m handle \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1371\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m   1372\u001b[0m                        run_metadata)\n\u001b[1;32m   1373\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/topic-segmentation-ivNeB2ii/lib/python3.10/site-packages/tensorflow/python/client/session.py:1378\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1376\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_do_call\u001b[39m(\u001b[39mself\u001b[39m, fn, \u001b[39m*\u001b[39margs):\n\u001b[1;32m   1377\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1378\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m   1379\u001b[0m   \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOpError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1380\u001b[0m     message \u001b[39m=\u001b[39m compat\u001b[39m.\u001b[39mas_text(e\u001b[39m.\u001b[39mmessage)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/topic-segmentation-ivNeB2ii/lib/python3.10/site-packages/tensorflow/python/client/session.py:1361\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1358\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_fn\u001b[39m(feed_dict, fetch_list, target_list, options, run_metadata):\n\u001b[1;32m   1359\u001b[0m   \u001b[39m# Ensure any changes to the graph are reflected in the runtime.\u001b[39;00m\n\u001b[1;32m   1360\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extend_graph()\n\u001b[0;32m-> 1361\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m   1362\u001b[0m                                   target_list, run_metadata)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/topic-segmentation-ivNeB2ii/lib/python3.10/site-packages/tensorflow/python/client/session.py:1454\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1452\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_tf_sessionrun\u001b[39m(\u001b[39mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1453\u001b[0m                         run_metadata):\n\u001b[0;32m-> 1454\u001b[0m   \u001b[39mreturn\u001b[39;00m tf_session\u001b[39m.\u001b[39;49mTF_SessionRun_wrapper(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session, options, feed_dict,\n\u001b[1;32m   1455\u001b[0m                                           fetch_list, target_list,\n\u001b[1;32m   1456\u001b[0m                                           run_metadata)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "importlib.reload(config)\n",
    "\n",
    "# Set the input directory.\n",
    "input_dir = \"data/wiki_727K/train\"\n",
    "tfrecord_tmpl = os.path.join(input_dir, config.tfrecord_tmpl)\n",
    "\n",
    "print(\"Number of training examples =\", get_batch_count(tfrecord_tmpl))\n",
    "print(\"Loading the word2vec model...\")\n",
    "_, embeddings = utils.load_wordvecs(config.word2vec_file_path, load_embs=True)\n",
    "print(\"Loaded wordvecs.\")\n",
    "\n",
    "model_conf = tf.estimator.RunConfig(model_dir=config.model_dir)\n",
    "estimator = tf.estimator.Estimator(model_fn=model_fn, config=model_conf, params={\"embeddings\": embeddings})\n",
    "\n",
    "print(\"Training...\")\n",
    "estimator.train(input_fn=lambda: input_fn(tfrecord_tmpl))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a399c338",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3b7d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(config)\n",
    "\n",
    "input_dir = \"data/wiki_727K/dev\"\n",
    "input_dir = \"data/ext\"\n",
    "tfrecord_tmpl = os.path.join(input_dir, config.tfrecord_tmpl)\n",
    "\n",
    "print(\"Number of evaluation examples =\", get_batch_count(tfrecord_tmpl))\n",
    "print(\"Loading the word2vec model...\")\n",
    "_, embeddings = utils.load_wordvecs(config.word2vec_file_path, load_embs=True)\n",
    "model_conf = tf.estimator.RunConfig(model_dir=config.model_dir)\n",
    "estimator = tf.estimator.Estimator(model_fn=model_fn, config=model_conf, params={\"embeddings\": embeddings})\n",
    "\n",
    "print(\"Evaluating...\")\n",
    "estimator.evaluate(input_fn=lambda: input_fn(tfrecord_tmpl))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f33037",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fff728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import shutil\n",
    "import predict\n",
    "importlib.reload(predict)\n",
    "\n",
    "input_file = \"100368.preprocessed\"\n",
    "tmp_dir = tempfile.mkdtemp()\n",
    "print(\"Working inside\", tmp_dir)\n",
    "shutil.copyfile(input_file, os.path.join(tmp_dir, os.path.basename(input_file)))\n",
    "predict.predict(tmp_dir)\n",
    "shutil.rmtree(tmp_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('topic-segmentation-ivNeB2ii')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "308329fb9302eea2f93cc6383e70862fead50bd007ea65607de08896eab4abea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
